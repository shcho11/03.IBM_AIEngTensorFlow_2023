{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shcho11/03.IBM_AIEngineering_TensorFlow/blob/main/202308_AIEngineering_finalproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKfmgwW47hrA"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>    \n",
        "\n",
        "1. <a href=\"#item41\">Download Data\n",
        "2. <a href=\"#item42\">Part 1</a>\n",
        "3. <a href=\"#item43\">Part 2</a>  \n",
        "4. <a href=\"#item44\">Part 3</a>  \n",
        "\n",
        "</font>\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAptL3wV7hrB"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-B-e-Qh7rYS",
        "outputId": "abedd299-fad3-40b0-dc17-3f897b325a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_YNBCCjEseor",
        "outputId": "a31d7aa0-c04b-4686-cecc-3243bffa20c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtSaxGCp7hrB",
        "outputId": "b135115b-8393-4ca7-8eba-5654a2efcadc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-22 14:45:53--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week4.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261483817 (249M) [application/zip]\n",
            "Saving to: ‘concrete_data_week4.zip’\n",
            "\n",
            "concrete_data_week4 100%[===================>] 249.37M  35.2MB/s    in 7.3s    \n",
            "\n",
            "2023-08-22 14:46:00 (34.3 MB/s) - ‘concrete_data_week4.zip’ saved [261483817/261483817]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week4.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2zkNvHB7hrC"
      },
      "outputs": [],
      "source": [
        "!unzip concrete_data_week4.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a"
      ],
      "metadata": {
        "id": "uBI0Cj_ws3PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUnBAK5g7hrD"
      },
      "source": [
        "After you unzip the data, you fill find the data has already been divided into a train, validation, and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUE9MS1b7hrD"
      },
      "source": [
        "## Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1sMGjyk7hrD"
      },
      "source": [
        "In this part, you will design a classifier using the VGG16 pre-trained model. Just like the ResNet50 model, you can import the model <code>VGG16</code> from <code>keras.applications</code>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLu8pn5x7hrD"
      },
      "source": [
        "You will essentially build your classifier as follows:\n",
        "1. Import libraries, modules, and packages you will need. Make sure to import the *preprocess_input* function from <code>keras.applications.vgg16</code>.\n",
        "2. Use a batch size of 100 images for both training and validation.\n",
        "3. Construct an ImageDataGenerator for the training set and another one for the validation set. VGG16 was originally trained on 224 × 224 images, so make sure to address that when defining the ImageDataGenerator instances.\n",
        "4. Create a sequential model using Keras. Add VGG16 model to it and dense layer.\n",
        "5. Compile the mode using the adam optimizer and the categorical_crossentropy loss function.\n",
        "6. Fit the model on the augmented data using the ImageDataGenerators."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56ZvEsjS7hrD"
      },
      "source": [
        "Use the following cells to create your classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_26S3Yc7hrE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "#import skillsnetwork\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klQ3wD4IWs0t"
      },
      "source": [
        "### Define Global Constants\n",
        "1. We are obviously dealing with two classes, so *num_classes* is 2.\n",
        "2. The VGG16 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
        "3. We will training and validating the model using batches of 100 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9puMsZD7hrE"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "image_resize = 224\n",
        "batch_size_training = 100\n",
        "batch_size_validation = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBTbYW5AXHc_"
      },
      "source": [
        "### Construct ImageDataGenerator Instances\n",
        "- In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aieROJde7hrE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTPpfZkxXYEq"
      },
      "source": [
        "- **flow_from_directory** method to get the training images as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYnV-YgS7hrE",
        "outputId": "2d6663ee-8cff-476f-cf31-6af7000f72e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30001 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week4/train',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_training,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qso2Hjc7hrE",
        "outputId": "14295ebf-855f-4087-d3dc-fed96f380c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9501 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week4/valid',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_validation,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njf3-o3lXjtG"
      },
      "source": [
        "### Build, Compile and Fit Model\n",
        "- In this section, we will start building our model. We will use the Sequential model class from Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y698SkQl7hrE"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTz6WDCN7hrF",
        "outputId": "1d924683-8fd2-4c08-bfa9-dbf43830e427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model.add(VGG16(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet',\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd_KXNsmYBns"
      },
      "source": [
        "- Then, we will define our output layer as a Dense layer, that consists of two nodes and uses the Softmax function as the activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNLYv34-7hrF"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlH7FwHt7hrF",
        "outputId": "eeb8b772-e5ec-4cf7-cf14-4299a12d32b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.functional.Functional at 0x79ea44996ad0>,\n",
              " <keras.layers.core.dense.Dense at 0x79ea44997850>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfHSSPSrYRwT"
      },
      "source": [
        "- You can see that our model is composed of two sets of layers. The first set is the layers pertaining to VGG16 and the second set is a single layer, which is our Dense layer that we defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvzQPJ1i7hrF",
        "outputId": "296e28d6-efa2-4ac7-a9fa-a7e2e7e4687e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x79ea46b43f70>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea45791660>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea45791db0>,\n",
              " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x79ea45792da0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea45793b50>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea45793c10>,\n",
              " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x79ea44968eb0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea457937c0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea4496a830>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea449697b0>,\n",
              " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x79ea4496be80>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea4496bfa0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea449693f0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea44981b70>,\n",
              " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x79ea44982c20>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea44982bf0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea44983880>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x79ea44983b20>,\n",
              " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x79ea44994fd0>,\n",
              " <keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x79ea44981de0>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model.layers[0].layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOZPgiz6YwAv"
      },
      "source": [
        "- Since the VGG16 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrDJhlon7hrF"
      },
      "outputs": [],
      "source": [
        "model.layers[0].trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FanlWUaY4_j"
      },
      "source": [
        "- And now using the summary attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWh34I2K7hrF",
        "outputId": "d2e406b3-815c-4159-ef99-ef2055c3f60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 512)               14714688  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,715,714\n",
            "Trainable params: 1,026\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wAA0Q64ZBoX"
      },
      "source": [
        "- Next we compile our model using the adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbk0CshE7hrF"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj0YUY1TZIRY"
      },
      "source": [
        "- Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhtfNG1y7hrF"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch_training = len(train_generator)\n",
        "steps_per_epoch_validation = len(validation_generator)\n",
        "num_epochs = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JX7wVLn7hrG",
        "outputId": "1c2e5277-a5f5-486d-f8f2-8d92e1568cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "301\n",
            "96\n"
          ]
        }
      ],
      "source": [
        "print(steps_per_epoch_training)\n",
        "print(steps_per_epoch_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipFFkgnwZcGb"
      },
      "source": [
        "- Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the fit_generator method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-k-tPKj7hrG",
        "outputId": "0627af91-0733-4464-a0df-9e30f447c686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-172e67583a70>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  fit_history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "301/301 [==============================] - 184s 543ms/step - loss: 0.1794 - accuracy: 0.9547 - val_loss: 0.0454 - val_accuracy: 0.9901\n",
            "Epoch 2/2\n",
            "301/301 [==============================] - 173s 573ms/step - loss: 0.0343 - accuracy: 0.9920 - val_loss: 0.0249 - val_accuracy: 0.9944\n"
          ]
        }
      ],
      "source": [
        "fit_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN0SqWHk7hrG"
      },
      "outputs": [],
      "source": [
        "model.save('classifier_vgg16_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKt_tYt1zp2t"
      },
      "outputs": [],
      "source": [
        "!cp classifier_vgg16_model.h5 drive/MyDrive/classifier_vgg16_model2.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfyA8BKK7hrG"
      },
      "source": [
        "## Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9n-3Y_g7hrG"
      },
      "source": [
        "In this part, you will evaluate your deep learning models on a test data. For this part, you will need to do the following:\n",
        "\n",
        "1. Load your saved model that was built using the ResNet50 model.\n",
        "2. Construct an ImageDataGenerator for the test set. For this ImageDataGenerator instance, you only need to pass the directory of the test images, target size, and the **shuffle** parameter and set it to False.\n",
        "3. Use the **evaluate_generator** method to evaluate your models on the test data, by passing the above ImageDataGenerator as an argument. You can learn more about **evaluate_generator** [here](https://keras.io/models/sequential/).\n",
        "4. Print the performance of the classifier using the VGG16 pre-trained model.\n",
        "5. Print the performance of the classifier using the ResNet pre-trained model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkutEBNR7hrV"
      },
      "source": [
        "Use the following cells to evaluate your models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0rIiddaenrt"
      },
      "outputs": [],
      "source": [
        "model_resnet = load_model('/content/drive/MyDrive/classifier_resnet_model2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUkpKHiS7hrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45e51c5-85f5-4b76-f26e-6f519e4fa1ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 500 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size_test = 100\n",
        "\n",
        "test_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week4/test',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_test,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "523FA6ov7hrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5191f187-24dc-490f-b446-8871f8c88a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-fb49b33d0ca4>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  score = model.evaluate_generator(test_generator, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 3s 455ms/step - loss: 0.0214 - accuracy: 0.9960\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate_generator(test_generator, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WynMWIit7hrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f669caf8-840c-4a1c-c43a-f9c25caf9f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss VGG16:  0.021432356908917427\n",
            "Accuracy VGG16:  0.9959999918937683\n"
          ]
        }
      ],
      "source": [
        "print(\"Loss VGG16: \", score[0])\n",
        "print(\"Accuracy VGG16: \", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYK6juDy7hrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e9060b-d3c4-4f28-c121-5111504426ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-bdd583a91e49>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  score_resnet = model_resnet.evaluate_generator(test_generator, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 6s 336ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Loss ResNet50:  0.0026115465443581343\n",
            "Accuracy ResNet50:  1.0\n"
          ]
        }
      ],
      "source": [
        "score_resnet = model_resnet.evaluate_generator(test_generator, verbose=1)\n",
        "\n",
        "print(\"Loss ResNet50: \", score_resnet[0])\n",
        "print(\"Accuracy ResNet50: \", score_resnet[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WoW.. Accuray socre of the ResNet50 shows 1.0. This does not necessarily mean 'Better' though."
      ],
      "metadata": {
        "id": "5lm6zRDdxCrO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQvnQBBJ7hrV"
      },
      "source": [
        "## Part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MVbSwRz7hrW"
      },
      "source": [
        "In this model, you will predict whether the images in the test data are images of cracked concrete or not. You will do the following:\n",
        "\n",
        "1. Use the **predict_generator** method to predict the class of the images in the test data, by passing the test data ImageDataGenerator instance defined in the previous part as an argument. You can learn more about the **predict_generator** method [here](https://keras.io/models/sequential/).\n",
        "2. Report the class predictions of the first five images in the test set. You should print something list this:\n",
        "\n",
        "<center>\n",
        "    <ul style=\"list-style-type:none\">\n",
        "        <li>Positive</li>  \n",
        "        <li>Negative</li>\n",
        "        <li>Positive</li>\n",
        "        <li>Positive</li>\n",
        "        <li>Negative</li>\n",
        "    </ul>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt6OIq4b7hrW"
      },
      "source": [
        "Use the following cells to make your predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dl-kH9m7hrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c2ae42-f567-411a-f885-4236c77e9de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-27c44ad6a4ea>:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  predict = model.predict_generator(test_generator, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 440ms/step\n"
          ]
        }
      ],
      "source": [
        "predict = model.predict_generator(test_generator, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ssV7DWU7hrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7d6c66-1d90-4b65-cf6f-225201aab250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG16 Predict 1 : [0.95831394 0.04168607]\n",
            "VGG16 Predict 2 : [0.9955711  0.00442899]\n",
            "VGG16 Predict 3 : [0.013183   0.98681706]\n",
            "VGG16 Predict 4 : [1.5037456e-04 9.9984956e-01]\n",
            "VGG16 Predict 5 : [4.7154215e-05 9.9995279e-01]\n"
          ]
        }
      ],
      "source": [
        "for i in range(5) :\n",
        "  print(f\"VGG16 Predict {i+1} : {predict[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictionv1(predict, int) :\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for i in range(int) :\n",
        "    item = predict[i][1]\n",
        "    if item > 0.5 :\n",
        "      results.append(\"Negative\")\n",
        "    else :\n",
        "      results.append(\"Positive\")\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "rtKklKiozcky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictionv2(predict, int) :\n",
        "\n",
        "  for i in range(int) :\n",
        "    if predict[i][0] > predict[i][1]:\n",
        "      print(\"Positive ({}% certainty)\".format(round(predict[i][0] * 100, 1)))\n",
        "    elif predict[i][0] < predict[i][1]:\n",
        "      print(\"Negative ({}% certainty)\".format(round(predict[i][1] * 100, 1)))\n",
        "    else:\n",
        "      print(\"Unsure (prediction split 50–50)\")"
      ],
      "metadata": {
        "id": "DoFXCFXt9qI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictionv1(predict,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-DFb34I0XE5",
        "outputId": "571bef23-83ec-457e-8f55-b31a33d68246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Positive', 'Positive', 'Negative', 'Negative', 'Negative']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictionv2(predict,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVyDO1Dy-33Y",
        "outputId": "0e18dc75-d9f2-426f-e69c-8936ed16ab68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive (95.8% certainty)\n",
            "Positive (99.6% certainty)\n",
            "Negative (98.7% certainty)\n",
            "Negative (100.0% certainty)\n",
            "Negative (100.0% certainty)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogavv3w97hrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b02ca6-1b99-4486-a6f6-e25b35404ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 312ms/step\n",
            "ResNet50 Predict 1 : [2.421712e-05 9.999758e-01]\n",
            "ResNet50 Predict 2 : [2.3056782e-04 9.9976939e-01]\n",
            "ResNet50 Predict 3 : [9.9981481e-01 1.8526161e-04]\n",
            "ResNet50 Predict 4 : [9.9974674e-01 2.5328551e-04]\n",
            "ResNet50 Predict 5 : [9.5287534e-05 9.9990475e-01]\n"
          ]
        }
      ],
      "source": [
        "predict_resnet = model_resnet.predict(test_generator, verbose=1)\n",
        "\n",
        "for i in range(5) :\n",
        "  print(f\"ResNet50 Predict {i+1} : {predict_resnet[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbCyLjPe7hrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7eef039-fd30-4501-e478-7fdb33036091"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Negative', 'Negative', 'Positive', 'Positive', 'Negative']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "predictionv1(predict_resnet,5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictionv2(predict_resnet,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSfBJzN__3of",
        "outputId": "a0a9d707-8885-4a17-aaa2-78243ea2b34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative (100.0% certainty)\n",
            "Negative (100.0% certainty)\n",
            "Positive (100.0% certainty)\n",
            "Positive (100.0% certainty)\n",
            "Negative (100.0% certainty)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cciWBvOQCBto"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}